{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METRIC-BASED META-LEARNING using Matching Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%cd drive/MyDrive/'Colab Notebooks'\n",
    "#%cd meta-learning-course-notebooks/1_MAML/\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install import_ipynb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install learn2learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import utils\n",
    "import models\n",
    "utils.hide_toggle('Imports 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from l2lutils import KShotLoader\n",
    "from IPython import display\n",
    "utils.hide_toggle('Imports 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data - euclidean\n",
    "meta_train_ds, meta_test_ds, full_loader = utils.euclideanDataset(n_samples=10000,n_features=20,n_classes=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an MLP network. Note that input dimension has to be data dimension. For classification\n",
    "# final dimension has to be number of classes; for regression one.\n",
    "#torch.manual_seed(10)\n",
    "net = models.MLP(dims=[20,32,32,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network; note that network is trained in place so repeated calls further train it.\n",
    "net,loss,accs=models.Train(net,full_loader,lr=1e-2,epochs=50,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training accuracy.\n",
    "models.accuracy(net,meta_train_ds.samples,meta_train_ds.labels,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy.\n",
    "models.accuracy(net,meta_test_ds.samples,meta_test_ds.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Learning: Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a k-shot n-way loader using the meta-training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_kloader=KShotLoader(meta_train_ds,shots=5,ways=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample a task - each task has a k-shot n-way training set and a similar test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train,d_test=meta_train_kloader.get_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try directly learning using the task training set albeit its small size: create a dataset and loader and train it with the earlier network and Train function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskds = utils.MyDS(d_train[0],d_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_loader = torch.utils.data.DataLoader(dataset=taskds,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net,loss,accs=models.Train(net,d_train_loader,lr=1e-1,epochs=10,verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it do on the test set of the sampled task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.accuracy(net,d_test[0],d_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learn2learn as l2l\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling a training task: Note that each of d_train and d_test is a tuple comprising of a training set, and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train,d_test=meta_train_kloader.get_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cos computes cosine similarities between a batch of targets and a given support set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cos(nn.Module):\n",
    "    def __init__(self,dims=[20,32,32]):\n",
    "        super(Cos,self).__init__()\n",
    "    def forward(self,target,ss):\n",
    "        # compute cosine distances between \n",
    "        # target (batch,embedding_dim) and support set ss (ss_size,embedding_dim)\n",
    "        # return (batch,ss_size)\n",
    "        target_normed = F.normalize(target,p=2,dim=1)\n",
    "        # shape of target_normed will be (batch,1,embedding_dim)\n",
    "        ss_normed = F.normalize(ss,p=2,dim=1).permute(1,0)\n",
    "        similarities = torch.mm(target_normed,ss_normed)\n",
    "        # result will be (batch,ss_size)\n",
    "        return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching Network (simple - without Full-context embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAN(nn.Module):\n",
    "    def __init__(self,dims=[20,32,32],n_classes=2,lr=1e-3):\n",
    "        super(MAN,self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.mlp = models.MLP(dims=dims,task='embedding')\n",
    "        self.cos = Cos()\n",
    "        self.attn = nn.Softmax(dim=1)\n",
    "        self.optimizer = optim.Adam(self.parameters(),lr=lr)\n",
    "    def forward(self,X,d_train):\n",
    "        # X = (batch,n_features)\n",
    "        (x_tr,y_tr) = d_train\n",
    "        # x_tr = (ss_size,n_features), y_tr = (ss_size)\n",
    "        ss_e = self.mlp(x_tr)\n",
    "        X_e = self.mlp(X)\n",
    "        sims = self.cos(X_e,ss_e)\n",
    "        # size (batch,ss_size)\n",
    "        attn_wts = self.attn(sims)\n",
    "        y_h = torch.eye(self.n_classes)[y_tr]\n",
    "        # y_h = one-hot version of y_tr = (ss_size,n_classes)\n",
    "        preds = attn_wts@y_h\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([[1,1,1],[-1,-1,-1],[1,2,3],[-1,-2,-3]])\n",
    "y_tr = torch.LongTensor([0,1])\n",
    "x_tr = X[[0,1],:]\n",
    "d_tr = (x_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man = MAN(dims=[3,8,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together: Training a Matching Network\n",
    "Now let's put all of the above in a loop - training Matching Network algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redifning accuracy function so that it takes h - dataset context - as input since net requires it.\n",
    "def accuracy(Net,X_test,y_test,h,verbose=True):\n",
    "    #Net.eval()\n",
    "    m = X_test.shape[0]\n",
    "    y_pred = Net(X_test,h)\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    correct = (predicted == y_test).float().sum().item()\n",
    "    if verbose: print(correct,m)\n",
    "    accuracy = correct/m\n",
    "    #Net.train()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_train = [i for i in range(5)]\n",
    "classes_test = [i+5 for i in range(5)]\n",
    "classes_train, classes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learn2learn as l2l\n",
    "import torch.optim as optim\n",
    "shots,ways = 5,5\n",
    "net = MAN(n_classes=ways,dims=[20,64,32],lr=1e-4)\n",
    "lossfn = torch.nn.NLLLoss()\n",
    "meta_train_kloader=KShotLoader(meta_train_ds,shots=shots,ways=ways,num_tasks=1000,classes=classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=0\n",
    "n_epochs=100\n",
    "task_count=50\n",
    "while epoch<n_epochs:\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    # Sample and train on a task\n",
    "    for task in range(task_count):\n",
    "        d_train,d_test=meta_train_kloader.get_task()\n",
    "        rp = torch.randperm(d_train[1].shape[0])\n",
    "        d_train0=d_train[0][rp]\n",
    "        d_train1=d_train[1][rp]\n",
    "        x_tr = d_train0\n",
    "        d_tr = x_tr \n",
    "        rp1 = torch.randperm(d_test[1].shape[0])\n",
    "        d_test0=d_test[0][rp1]\n",
    "        d_test1=d_test[1][rp1]\n",
    "        x_ts = d_test0\n",
    "        d_ts = x_ts \n",
    "        test_preds = net(d_ts,(x_tr,d_train1))\n",
    "        #train_preds = net(d_tr,h)\n",
    "        # Accumulate losses over tasks - note train and test loss both included\n",
    "        test_loss += lossfn(test_preds,d_test1)\n",
    "        net.eval()\n",
    "        test_acc += accuracy(net,d_ts,d_test1,(x_tr,d_train1),verbose=False)\n",
    "        net.train()\n",
    "    #Update the network weights\n",
    "    print('Epoch  % 2d Loss: %2.5e Avg Acc: %2.5f'%(epoch,test_loss/task_count,test_acc/task_count))\n",
    "    display.clear_output(wait=True)\n",
    "    net.optimizer.zero_grad()\n",
    "    test_loss.backward()\n",
    "    net.optimizer.step()\n",
    "    epoch+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the trained CNP network and to tasks sampled from the meta_test_ds dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test_kloader=KShotLoader(meta_test_ds,shots=shots,ways=ways,classes=classes_test)\n",
    "test_acc = 0.0\n",
    "task_count = 50\n",
    "adapt_steps = 1\n",
    "# Sample and train on a task\n",
    "for task in range(task_count):\n",
    "    d_train,d_test=meta_test_kloader.get_task()\n",
    "    x_tr = d_train[0]\n",
    "    y_tr_sh = torch.cat((torch.zeros(1,ways),torch.eye(ways)[d_train[1][1:]]))\n",
    "    d_tr = x_tr #torch.cat((x_tr,y_tr_sh),1)\n",
    "    x_ts = d_test[0]\n",
    "    y_ts_sh = torch.zeros(x_ts.shape[0],ways)\n",
    "    d_ts = x_ts #torch.cat((x_ts,y_ts_sh),1)\n",
    "    test_preds = net(d_ts,(d_tr,d_train[1]))\n",
    "    test_acc += accuracy(net,d_ts,d_test[1],(d_tr,d_train[1]),verbose=False)\n",
    "    # Done with a task\n",
    "net.train()\n",
    "print('Avg Acc: %2.5f'%(test_acc/task_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
