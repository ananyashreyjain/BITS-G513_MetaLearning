{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TO BE DONE </b> Need to fix - accumulate class-specific representations somehow???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL-BASED META-LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%cd drive/MyDrive/'Colab Notebooks'\n",
    "#%cd meta-learning-course-notebooks/1_MAML/\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install import_ipynb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install learn2learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from models.ipynb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_4640893882310106271() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_4640893882310106271()\"><b>Imports 1</b> (show/hide)</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import utils\n",
    "import models\n",
    "utils.hide_toggle('Imports 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from l2lutils.ipynb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_16791868985676098106() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_16791868985676098106()\"><b>Imports 2</b> (show/hide)</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from l2lutils import KShotLoader\n",
    "from IPython import display\n",
    "import torch.nn as nn\n",
    "utils.hide_toggle('Imports 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation/Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data - euclidean\n",
    "meta_train_ds, meta_test_ds, full_loader = utils.euclideanDataset(n_samples=10000,n_features=20,n_classes=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data - sinusoidal mix\n",
    "meta_train_ds, meta_test_ds, full_loader = utils.sinDataset(n_samples=10000,length=20,n_classes=10,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_ds, meta_test_ds, full_loader = utils.mnist_data(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an MLP network. Note that input dimension has to be data dimension. For classification\n",
    "# final dimension has to be number of classes; for regression one.\n",
    "#torch.manual_seed(10)\n",
    "net = models.MLP(dims=[20,64,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   49 Loss: 2.79184e-02 Accuracy: 0.99441\n"
     ]
    }
   ],
   "source": [
    "# Train the network; note that network is trained in place so repeated calls further train it.\n",
    "net,losses,accs=models.Train(net,full_loader,lr=1e-2,epochs=50,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7461.0 7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9948"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training accuracy.\n",
    "models.accuracy(net,meta_train_ds.samples,meta_train_ds.labels,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2437.0 2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9748"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy.\n",
    "models.accuracy(net,meta_test_ds.samples,meta_test_ds.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Learning: Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a k-shot n-way loader using the meta-training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_kloader=KShotLoader(meta_train_ds,shots=5,ways=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample a task - each task has a k-shot n-way training set and a similar test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train,d_test=meta_train_kloader.get_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try directly learning using the task training set albeit its small size: create a dataset and loader and train it with the earlier network and Train function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskds = utils.MyDS(d_train[0],d_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_loader = torch.utils.data.DataLoader(dataset=taskds,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 Loss: 2.16691e-03 Accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "net,losses,accs=models.Train(net,d_train_loader,lr=1e-1,epochs=10,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it do on the test set of the sampled task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.accuracy(net,d_test[0],d_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN-based  Meta-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisers from torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a task dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_kloader=KShotLoader(meta_train_ds,shots=5,ways=2)\n",
    "d_train,d_test=meta_train_kloader.get_task()\n",
    "d_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)[d_train[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp = torch.randperm(d_train[1].shape[0])\n",
    "rp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train[1][rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6395e+00, -1.0341e-01, -2.7567e+00, -1.0516e+00,  2.5619e-01,\n",
       "          -2.7568e+00,  2.7967e+00,  7.7783e-01,  2.1391e+00, -5.7535e+00,\n",
       "           5.5501e+00, -3.4873e+00,  3.1777e+00, -1.6247e+00,  1.7609e+00,\n",
       "          -2.9889e+00, -7.4840e-01,  6.1628e+00,  4.8930e+00,  2.0629e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.4736e+00,  1.3376e+00,  1.0804e+00,  6.4915e+00,  1.2641e+00,\n",
       "          -6.6149e+00, -7.1724e+00, -3.9562e+00,  7.3679e-01,  3.1166e-01,\n",
       "          -9.6249e-01,  7.9612e+00,  1.6754e+00, -4.1313e-01, -3.8431e+00,\n",
       "           5.4754e+00, -8.2477e-01,  1.0071e+00, -2.1848e+00,  5.8258e+00,\n",
       "           0.0000e+00,  1.0000e+00],\n",
       "         [-3.2002e+00, -4.0640e+00, -8.9914e-01,  5.5658e+00, -3.0332e-01,\n",
       "          -2.6130e+00, -2.5447e+00,  3.0098e+00,  7.4563e+00,  3.5086e+00,\n",
       "           2.2753e+00, -1.1553e+00, -1.4931e+00, -4.0984e+00, -4.2317e+00,\n",
       "           3.7498e+00, -1.0773e+00,  7.4660e+00,  5.5761e-02, -1.9429e+00,\n",
       "           1.0000e+00,  0.0000e+00],\n",
       "         [-6.6408e-01, -3.2469e+00,  5.8011e+00,  2.0800e-03,  2.8247e+00,\n",
       "          -1.6755e+00,  2.0453e+00,  1.8264e+00,  8.1089e+00, -5.5885e+00,\n",
       "           2.3324e+00,  1.4370e+00,  4.7968e+00, -2.6105e+00, -2.6381e+00,\n",
       "           1.3368e+00,  5.9077e-01, -1.8539e+00,  5.2269e+00, -2.3315e+00,\n",
       "           0.0000e+00,  1.0000e+00],\n",
       "         [ 4.9538e+00,  3.9056e-01,  4.9527e+00,  2.6684e+00,  4.1725e-01,\n",
       "          -1.3334e+00, -5.2694e+00, -4.9007e-01, -5.8640e-02, -3.0340e+00,\n",
       "           5.8247e+00,  3.1752e+00,  2.1596e+00,  3.0265e+00, -2.5728e+00,\n",
       "           3.8172e+00,  5.2775e+00,  3.3033e+00,  5.3559e+00,  4.4798e+00,\n",
       "           0.0000e+00,  1.0000e+00],\n",
       "         [-5.4232e+00, -2.2550e+00, -1.2982e+00,  1.0110e+00, -4.0499e+00,\n",
       "          -2.6273e+00, -2.2677e+00, -9.2797e-02,  1.4611e+00,  1.9641e+00,\n",
       "           1.5159e+00, -1.3257e+00,  2.3449e+00, -3.0741e-01, -5.4530e+00,\n",
       "           7.3338e-01, -4.2206e+00, -1.4591e+00,  1.9137e+00,  7.0988e-02,\n",
       "           1.0000e+00,  0.0000e+00],\n",
       "         [ 1.4796e+00,  3.7412e+00, -8.1673e-01,  5.8274e+00,  2.0472e+00,\n",
       "          -7.6649e-01, -2.9108e+00,  1.6636e-02,  8.9882e-01, -3.5166e-01,\n",
       "          -4.1198e-01,  4.7916e+00,  1.1223e+00,  2.8154e+00, -1.8766e+00,\n",
       "           5.3011e+00, -6.2631e-01,  4.8279e+00, -1.2406e+00,  5.6003e+00,\n",
       "           0.0000e+00,  1.0000e+00],\n",
       "         [-3.6690e+00,  1.2602e+00, -1.0390e-01,  4.2530e+00,  7.7077e-01,\n",
       "          -6.1667e+00, -2.6287e+00,  2.6362e+00,  2.3190e+00,  3.8351e+00,\n",
       "           4.8656e+00,  5.2721e-01,  9.5370e-01, -9.2315e-01, -5.9095e+00,\n",
       "           3.0222e+00, -4.0196e+00,  3.7430e+00,  4.6429e+00, -3.0672e+00,\n",
       "           1.0000e+00,  0.0000e+00],\n",
       "         [ 3.1005e+00,  3.7590e+00,  1.3280e+00,  3.4057e+00,  5.6565e+00,\n",
       "          -3.8567e+00, -7.6865e-01,  2.4238e+00,  5.0125e-01, -1.6418e+00,\n",
       "           3.1981e+00,  1.8547e+00,  1.9319e+00,  3.2426e+00, -2.6261e+00,\n",
       "           5.9305e+00,  2.4845e+00,  1.1197e+00,  1.2519e+00, -1.6569e+00,\n",
       "           0.0000e+00,  1.0000e+00],\n",
       "         [-2.8237e+00, -2.6859e+00, -5.0518e+00,  3.8080e+00, -1.9879e+00,\n",
       "          -3.1590e+00, -1.8164e+00,  3.0168e+00,  2.6502e-01,  3.5510e+00,\n",
       "           3.1683e+00, -2.6565e-01,  9.1580e-01, -8.5723e-01, -4.8527e+00,\n",
       "           4.1654e+00, -2.7179e+00,  2.4083e+00,  4.3207e+00,  5.5122e-01,\n",
       "           1.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp = torch.randperm(d_train[1].shape[0])\n",
    "d_train0=d_train[0][rp]\n",
    "d_train1=d_train[1][rp]\n",
    "x_tr = d_train0\n",
    "y_tr_sh = torch.cat((torch.zeros(1,2),torch.eye(2)[d_train1[1:]]))\n",
    "d_tr = torch.cat((x_tr,y_tr_sh),1).unsqueeze(0)\n",
    "d_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 22])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ways=2\n",
    "x_ts = d_test[0]\n",
    "y_ts_sh = torch.zeros(x_ts.shape[0],ways)\n",
    "d_ts = torch.cat((x_ts,y_ts_sh),1).unsqueeze(0)\n",
    "d_ts = d_ts.transpose(0,1)\n",
    "d_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9344,  1.5836,  1.0684, -2.2639, -0.8146,  1.2077,  2.6714, -0.0248,\n",
       "         -4.1279, -1.7877, -1.8038,  1.1179,  7.6285, -1.3590,  2.6585, -7.1441,\n",
       "          2.3288, -0.0843,  2.6419, -2.9637,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent meta-learning network using GRU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_5815761925467585451() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_5815761925467585451()\"><b>Class MetaRNN</b> (show/hide)</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MetaRNN(nn.Module):\n",
    "    def __init__(self,n_features=1,dim=5,n_layers=2,n_classes=2,lr=1e-3):\n",
    "        super(MetaRNN,self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dim = dim\n",
    "        self.n_features = n_features\n",
    "        self.rnn = nn.GRU(n_features, dim, n_layers,batch_first=True)\n",
    "        self.linear = nn.Linear(dim,n_classes)\n",
    "        #self.linear2 = nn.Linear(dim,n_classes)\n",
    "        self.logsoft = nn.LogSoftmax(dim=-1)\n",
    "        self.optimizer = optim.Adam(self.parameters(),lr=lr)\n",
    "        self.h = torch.randn(self.n_layers,1,self.dim)\n",
    "        self.H = 0\n",
    "    def adapt(self,X,h):\n",
    "        if self.n_features==1: X=X.unsqueeze(-1)\n",
    "        #h = h.repeat(1,X.shape[0],1)\n",
    "        R = self.rnn(X,h)\n",
    "        #self.H = R[0]\n",
    "        G = self.logsoft(self.linear(R[0][-1,:,:]))\n",
    "        return G,R[1]\n",
    "    def forward(self,Y,h):\n",
    "        if self.n_features==1: Y=Y.unsqueeze(-1)\n",
    "        h = h.repeat(1,Y.shape[0],1)\n",
    "        R = self.rnn(Y,h)\n",
    "        #H = self.rnn(Y,h)[1]\n",
    "        #YH = torch.cat((Y,self.H.squeeze().repeat(Y.shape[0],1)),dim=1)\n",
    "        G = self.logsoft(self.linear(R[0][:,-1,:]))\n",
    "        return G\n",
    "utils.hide_toggle('Class MetaRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MetaRNN(n_features=22,dim=8,n_layers=2,n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 22])\n",
      "torch.Size([24, 8])\n",
      "torch.Size([24])\n",
      "torch.Size([24])\n",
      "torch.Size([24, 8])\n",
      "torch.Size([24, 8])\n",
      "torch.Size([24])\n",
      "torch.Size([24])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 25])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4046, -1.9978, -1.7352, -1.1966, -1.9641],\n",
       "        [-1.4969, -1.9738, -1.5423, -1.2812, -1.9264],\n",
       "        [-1.4638, -1.8917, -1.4706, -1.4604, -1.8585],\n",
       "        [-1.4629, -1.8077, -1.4419, -1.6391, -1.7500],\n",
       "        [-1.5763, -1.7180, -1.4604, -1.6710, -1.6417],\n",
       "        [-1.5688, -1.6912, -1.5446, -1.5566, -1.6974],\n",
       "        [-1.6767, -1.7307, -1.5502, -1.4857, -1.6230],\n",
       "        [-1.6788, -1.7575, -1.5471, -1.4686, -1.6206],\n",
       "        [-1.7384, -1.7476, -1.5931, -1.4303, -1.5729],\n",
       "        [-1.7260, -1.7656, -1.5954, -1.4204, -1.5776]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.adapt(d_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts = d_test[0]\n",
    "y_ts_sh = torch.cat((torch.zeros(1,5),torch.eye(5)[d_test[1][1:]]))\n",
    "d_ts = torch.cat((x_ts,y_ts_sh),1).unsqueeze(0)\n",
    "d_tst = d_ts.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3580, -1.5737, -1.9797, -1.6276, -1.6043],\n",
       "        [-1.4467, -1.5260, -1.8509, -1.7263, -1.5502],\n",
       "        [-1.3854, -1.5374, -1.8727, -1.6579, -1.6576],\n",
       "        [-1.3509, -1.5378, -1.9649, -1.6772, -1.6141],\n",
       "        [-1.3626, -1.5288, -1.9011, -1.6762, -1.6569],\n",
       "        [-1.4147, -1.5852, -1.8353, -1.6604, -1.5971],\n",
       "        [-1.4390, -1.4768, -1.8588, -1.6957, -1.6340],\n",
       "        [-1.4209, -1.5337, -1.8700, -1.6891, -1.5897],\n",
       "        [-1.3588, -1.5485, -1.9012, -1.6929, -1.6240],\n",
       "        [-1.4791, -1.4463, -1.8121, -1.7273, -1.6313],\n",
       "        [-1.3365, -1.4970, -1.9551, -1.7075, -1.6578],\n",
       "        [-1.3472, -1.5937, -1.9322, -1.6448, -1.6146],\n",
       "        [-1.3482, -1.5929, -1.9156, -1.6533, -1.6180],\n",
       "        [-1.3478, -1.6392, -1.9392, -1.6121, -1.5958],\n",
       "        [-1.3189, -1.5446, -1.9433, -1.6522, -1.6912],\n",
       "        [-1.3946, -1.5239, -1.9424, -1.6652, -1.6010],\n",
       "        [-1.4694, -1.5483, -1.8042, -1.6300, -1.6256],\n",
       "        [-1.3571, -1.5789, -1.9666, -1.6729, -1.5665],\n",
       "        [-1.3687, -1.5965, -1.9892, -1.6185, -1.5704],\n",
       "        [-1.4477, -1.5018, -1.8932, -1.6218, -1.6397],\n",
       "        [-1.3635, -1.5197, -1.8637, -1.7656, -1.6131],\n",
       "        [-1.3846, -1.5346, -1.7986, -1.7042, -1.6789],\n",
       "        [-1.4123, -1.5036, -1.7868, -1.6805, -1.7130],\n",
       "        [-1.4095, -1.5631, -1.8645, -1.6964, -1.5705],\n",
       "        [-1.3938, -1.5757, -1.7886, -1.7340, -1.6033]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(d_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5979, -1.4704, -1.5418, -1.7355, -1.7286]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(d_tst[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4523, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = net(d_test[0])\n",
    "train_loss = lossfn(preds,d_test[1])\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together: RNN-based Meta-learning\n",
    "Now let's put all of the above in a loop - the MAML algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Net,X_test,y_test,h,verbose=True):\n",
    "    #Net.eval()\n",
    "    m = X_test.shape[0]\n",
    "    y_pred = Net(X_test,h)\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    correct = (predicted == y_test).float().sum().item()\n",
    "    if verbose: print(correct,m)\n",
    "    accuracy = correct/m\n",
    "    #Net.train()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learn2learn as l2l\n",
    "import torch.optim as optim\n",
    "shots,ways = 5,2\n",
    "net = MetaRNN(n_features=20+ways,n_classes=ways,dim=20,n_layers=1,lr=1e-3)\n",
    "lossfn = torch.nn.NLLLoss()\n",
    "meta_train_kloader=KShotLoader(meta_train_ds,shots=shots,ways=ways,num_tasks=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   99 Loss: 1.34478e+00 Avg Acc: 0.30000\n"
     ]
    }
   ],
   "source": [
    "from functools import partial \n",
    "epoch=0\n",
    "n_epochs=100\n",
    "task_count=1\n",
    "fas=10\n",
    "while epoch<n_epochs:\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    # Sample and train on a task\n",
    "    for task in range(task_count):\n",
    "        d_train,d_test=meta_train_kloader.get_task()\n",
    "        rp = torch.randperm(d_train[1].shape[0])\n",
    "        d_train0=d_train[0]#[rp]\n",
    "        d_train1=d_train[1]#[rp]\n",
    "        x_tr = d_train0\n",
    "        #y_tr_sh = torch.cat((torch.zeros(1,ways),torch.eye(ways)[d_train1[1:]]))\n",
    "        y_tr_sh = torch.eye(ways)[d_train1]\n",
    "        d_tr = torch.cat((x_tr,y_tr_sh),1).unsqueeze(0)\n",
    "        d_trt = d_tr.transpose(0,1)\n",
    "        h = net.h\n",
    "        for fa in range(fas):\n",
    "            _,h = net.adapt(d_tr,h)\n",
    "        #_,h = net.adapt(d_tr,h)\n",
    "        rp1 = torch.randperm(d_test[1].shape[0])\n",
    "        d_test0=d_test[0]#[rp1]\n",
    "        d_test1=d_test[1]#[rp1]\n",
    "        x_ts = d_test0\n",
    "        y_ts_sh = torch.zeros(x_ts.shape[0],ways)\n",
    "        d_ts = torch.cat((x_ts,y_ts_sh),1).unsqueeze(0)\n",
    "        d_tst = d_ts.transpose(0,1)\n",
    "        test_preds = net(d_tst,h)\n",
    "        train_preds = net(d_trt,h)\n",
    "        test_loss += lossfn(test_preds,d_test1)+lossfn(train_preds,d_train1)\n",
    "        #net.eval()\n",
    "        #nf = partial(net,h=h)\n",
    "        test_acc += accuracy(net,d_tst,d_test1,h,verbose=False)\n",
    "        #net.train()\n",
    "        # Done with a task\n",
    "        # Update main network\n",
    "    print('Epoch  % 2d Loss: %2.5e Avg Acc: %2.5f'%(epoch,test_loss/task_count,test_acc/task_count))\n",
    "    display.clear_output(wait=True)\n",
    "    net.optimizer.zero_grad()\n",
    "    test_loss.backward(retain_graph=True,create_graph=True)\n",
    "    net.optimizer.step()\n",
    "    epoch+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the trained maml network and applying the adaption step to tasks sampled from the meta_test_ds dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.46800\n"
     ]
    }
   ],
   "source": [
    "meta_test_kloader=KShotLoader(meta_test_ds,shots=5,ways=ways)\n",
    "test_acc = 0.0\n",
    "task_count = 50\n",
    "adapt_steps = 1\n",
    "# Sample and train on a task\n",
    "for task in range(task_count):\n",
    "    d_train,d_test=meta_test_kloader.get_task()\n",
    "    x_tr = d_train[0]\n",
    "    y_tr_sh = torch.cat((torch.zeros(1,ways),torch.eye(ways)[d_train[1][1:]]))\n",
    "    d_tr = torch.cat((x_tr,y_tr_sh),1).unsqueeze(0)\n",
    "    h=net.h\n",
    "    net.adapt(d_tr,h)\n",
    "    x_ts = d_test[0]\n",
    "    y_ts_sh = torch.zeros(x_ts.shape[0],ways)\n",
    "    d_ts = torch.cat((x_ts,y_ts_sh),1).unsqueeze(0)\n",
    "    d_tst = d_ts.transpose(0,1)\n",
    "    test_preds = net(d_tst)\n",
    "    test_acc += models.accuracy(net,d_tst,d_test[1],verbose=False)\n",
    "    # Done with a task\n",
    "net.train()\n",
    "print('Avg Acc: %2.5f'%(test_acc/task_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 1, 0, 8, 7, 4, 5, 9, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
